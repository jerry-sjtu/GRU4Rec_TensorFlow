{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_steps = 5 # number of truncated backprop steps ('n' in the discussion above)\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 4\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "\n",
    "# adapted from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "\n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    # further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)\n",
    "\n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Placeholders\n",
    "\"\"\"\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "\"\"\"\n",
    "RNN Inputs\n",
    "\"\"\"\n",
    "\n",
    "# Turn our x placeholder into a list of one-hot tensors:\n",
    "# rnn_inputs is a list of num_steps tensors with shape [batch_size, num_classes]\n",
    "x_one_hot = tf.one_hot(x, num_classes)\n",
    "rnn_inputs = tf.unstack(x_one_hot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definition of rnn_cell\n",
    "\n",
    "This is very similar to the __call__ method on Tensorflow's BasicRNNCell. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py#L95\n",
    "\"\"\"\n",
    "# with tf.variable_scope('rnn_cell'):\n",
    "#     W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "#     b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "# def rnn_cell(rnn_input, state):\n",
    "#     with tf.variable_scope('rnn_cell', reuse=True):\n",
    "#         W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "#         b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "#     return tf.tanh(tf.matmul(tf.concat([rnn_input, state], 1), W) + b)\n",
    "\n",
    "\"\"\"\n",
    "Adding rnn_cells to graph\n",
    "\n",
    "This is a simplified version of the \"static_rnn\" function from Tensorflow's api. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn.py#L41\n",
    "Note: In practice, using \"dynamic_rnn\" is a better choice that the \"static_rnn\":\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py#L390\n",
    "\"\"\"\n",
    "# state = init_state\n",
    "# rnn_outputs = []\n",
    "# for rnn_input in rnn_inputs:\n",
    "#     state = rnn_cell(rnn_input, state)\n",
    "#     rnn_outputs.append(state)\n",
    "# final_state = rnn_outputs[-1]\n",
    "\n",
    "# tensorflow style\n",
    "cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "rnn_outputs, final_state = tf.contrib.rnn.static_rnn(cell, rnn_inputs, initial_state=init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predictions, loss, training step\n",
    "\n",
    "Losses is similar to the \"sequence_loss\"\n",
    "function from Tensorflow's API, except that here we are using a list of 2D tensors, instead of a 3D tensor. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/loss.py#L30\n",
    "\"\"\"\n",
    "\n",
    "#logits and predictions\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n",
    "# Turn our y placeholder into a list of labels\n",
    "y_as_list = tf.unstack(y, num=num_steps, axis=1)\n",
    "\n",
    "#losses and train_step\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit) for \\\n",
    "          logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train the network\n",
    "\"\"\"\n",
    "\n",
    "def train_network(num_epochs, num_steps, state_size=4, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses, total_loss, final_state, train_step],feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step,\n",
    "                              \"for last 250 steps:\", training_loss/100)\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "\n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 0\n",
      "Average loss at step 100 for last 250 steps: 0.5718621701\n",
      "Average loss at step 200 for last 250 steps: 0.528280007541\n",
      "Average loss at step 300 for last 250 steps: 0.522027240098\n",
      "Average loss at step 400 for last 250 steps: 0.521375950873\n",
      "Average loss at step 500 for last 250 steps: 0.522047789097\n",
      "Average loss at step 600 for last 250 steps: 0.520627300441\n",
      "Average loss at step 700 for last 250 steps: 0.52238158524\n",
      "Average loss at step 800 for last 250 steps: 0.518420760036\n",
      "Average loss at step 900 for last 250 steps: 0.520254715979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c1f716cc0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFxHJIQp9EZEc8v8BOvhbcRxYNLQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c1f6589e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = train_network(1,num_steps)\n",
    "plt.plot(training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
